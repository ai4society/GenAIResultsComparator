{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23a142ad-a0f4-4704-a725-9a419a8d2db3",
   "metadata": {},
   "source": [
    "# Prompt-Response Aggregation Similarity Score Example\n",
    "\n",
    "This notebook demonstrates how to use the Prompt-Response Aggregation Similarity Metric to evaluate how well responses align with their prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b7f691-918a-4a65-a852-c25ac29366a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.llm_aware_metrics.code.aggregated_similarity_score import AggregatedSimilarityMetric\n",
    "from llm_metrics.semantic_similarity_metrics import BERTScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a67d2f-8f0c-45e6-8b59-911e93b451c7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc7419-5033-45ce-9e6e-14399ada9d2c",
   "metadata": {},
   "source": [
    "## Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd95bb05-f64a-4528-a2a2-7394feb97e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"What are the main causes of climate change?\"\n",
    "\n",
    "# Well-aligned response\n",
    "response1 = \"The main causes of climate change include greenhouse gas emissions from burning fossil fuels, deforestation, and industrial processes.\"\n",
    "\n",
    "# Partially aligned response\n",
    "response2 = \"Climate change is a serious issue. We need to reduce pollution and plant more trees.\"\n",
    "\n",
    "# Poorly aligned response\n",
    "response3 = \"The weather has been quite unusual lately. Yesterday it rained all day.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6f2ca5-274f-4b4c-bf0a-f5948393b850",
   "metadata": {},
   "source": [
    "## Using the Aggregation Similarity Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6c1675-f7c1-4212-bffb-bca83a421c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the metric\n",
    "base_metric = BERTScore(model_type=\"microsoft/deberta-xlarge-mnli\")\n",
    "agg_metric = AggregatedSimilarityMetric(base_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad7c6c4-3979-4247-b2ae-267b8062c9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Similarity score for well-aligned responses:\n",
      "{'precision': 0.6514176527659098, 'recall': 0.5639405051867167, 'f1': 0.600588838259379}\n"
     ]
    }
   ],
   "source": [
    "# Compare well-aligned responses\n",
    "score1 = agg_metric.calculate_with_prompt(\n",
    "    response1,\n",
    "    response2,\n",
    "    prompt1\n",
    ")\n",
    "\n",
    "print(f\"Aggregated Similarity score for well-aligned responses:\\n{score1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8b1b32-d05e-42cc-bc3c-eb7ca0cf1e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Similarity score with poorly aligned response:\n",
      "{'precision': 0.5123771925767263, 'recall': 0.4340182642141978, 'f1': 0.4655380845069885}\n"
     ]
    }
   ],
   "source": [
    "# Compare with poorly aligned response\n",
    "score2 = agg_metric.calculate_with_prompt(\n",
    "    response1,\n",
    "    response3,\n",
    "    prompt1\n",
    ")\n",
    "\n",
    "print(f\"Aggregated Similarity score with poorly aligned response:\\n{score2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59decc0b-c789-43dd-be97-a187b46cde3d",
   "metadata": {},
   "source": [
    "## Analyzing Components of the Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78361c1-3f19-443f-bbc9-a98354128b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of well-aligned responses:\n",
      "\n",
      "Response 1 Prompt Aggregation:\n",
      "{'precision': 0.7984908819198608, 'recall': 0.5745624899864197, 'f1': 0.6682667136192322}\n",
      "Response 2 Prompt Aggregation:\n",
      "{'precision': 0.6100817918777466, 'recall': 0.5354424715042114, 'f1': 0.5703305006027222}\n",
      "Response Similarity:\n",
      "{'precision': 0.5456802845001221, 'recall': 0.581816554069519, 'f1': 0.5631693005561829}\n",
      "\n",
      "Analysis with poorly aligned response:\n",
      "\n",
      "Response 1 Prompt Aggregation:\n",
      "{'precision': 0.7984908819198608, 'recall': 0.5745624899864197, 'f1': 0.6682667136192322}\n",
      "Response 2 Prompt Aggregation:\n",
      "{'precision': 0.4078367352485657, 'recall': 0.34359011054039, 'f1': 0.3729669153690338}\n",
      "Response Similarity:\n",
      "{'precision': 0.3308039605617523, 'recall': 0.3839021921157837, 'f1': 0.3553806245326996}\n"
     ]
    }
   ],
   "source": [
    "# Let's break down the components of the aggregation score\n",
    "def analyze_aggregation(response1, response2, prompt):\n",
    "    # Get individual components\n",
    "    agg1 = agg_metric.calculate_prompt_aggregation(prompt, response1)\n",
    "    agg2 = agg_metric.calculate_prompt_aggregation(prompt, response2)\n",
    "    response_similarity = base_metric.calculate(response1, response2)\n",
    "    \n",
    "    print(f\"Response 1 Prompt Aggregation:\\n{agg1}\")\n",
    "    print(f\"Response 2 Prompt Aggregation:\\n{agg2}\")\n",
    "    print(f\"Response Similarity:\\n{response_similarity}\")\n",
    "\n",
    "print(\"Analysis of well-aligned responses:\\n\")\n",
    "analyze_aggregation(response1, response2, prompt1)\n",
    "\n",
    "print(\"\\nAnalysis with poorly aligned response:\\n\")\n",
    "analyze_aggregation(response1, response3, prompt1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
